version: "3"

networks:
  docker-direct:
    external: true

services:
  serge:
    image: 'ghcr.io/serge-chat/serge:latest'
    container_name: serge
    expose:
      # expose this port as this is not done in the original docker file
      - 8008
    restart: unless-stopped
    networks:
      - docker-direct
    volumes:
      - $DATA_DIR/serge-ai/weights:/usr/src/app/weights
      - $DATA_DIR/serge-ai/data:/data/db
    labels:
      caddy: serge-ai.hub
      caddy.tls: internal
      caddy.reverse_proxy: "{{upstreams 8008}}"

  chat-gpt:
    image: ghcr.io/mckaywrigley/chatbot-ui:main
    container_name: chat-gpt
    restart: unless-stopped
    networks:
      - docker-direct
    environment:
#      - 'OPENAI_API_HOST=http://ai:8080'
      - OPENAI_API_KEY
      - OPENAI_ORGANIZATION
      - DEFAULT_MODEL=gpt-4
      - GOOGLE_API_KEY
      - GOOGLE_CSE_ID
    labels:
      caddy: chat-gpt.hub
      caddy.tls: internal
      caddy.reverse_proxy: "{{upstreams 3000}}"

  ai:
    image: quay.io/go-skynet/local-ai:latest
    container_name: ai
    restart: unless-stopped
    networks:
      - docker-direct
    environment:
      - DEBUG=false
      - MODELS_PATH=/models
    volumes:
      - $DATA_DIR/local-ai/models:/models:cached
    command: [ "/usr/bin/local-ai" ]
    labels:
      caddy: ai.hub
      caddy.tls: internal
      caddy.reverse_proxy: "{{upstreams 8080}}"
