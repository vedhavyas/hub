version: "3"

networks:
  docker-direct:
    external: true

services:
  chat-gpt:
    image: ghcr.io/mckaywrigley/chatbot-ui:main
    container_name: chat-gpt
    restart: unless-stopped
    networks:
      - docker-direct
    environment:
#      - 'OPENAI_API_HOST=http://ai:8080'
      - OPENAI_API_KEY
      - OPENAI_ORGANIZATION
      - DEFAULT_MODEL=gpt-4o
      - GOOGLE_API_KEY
      - GOOGLE_CSE_ID
    labels:
      caddy: chat-gpt.hub
      caddy.tls: internal
      caddy.reverse_proxy: "{{upstreams 3000}}"

  ai:
    image: quay.io/go-skynet/local-ai:latest
    container_name: ai
    restart: unless-stopped
    networks:
      - docker-direct
    environment:
      - DEBUG=false
      - MODELS_PATH=/models
    volumes:
      - $DATA_DIR/local-ai/models:/models:cached
    command: [ "/usr/bin/local-ai" ]
    labels:
      caddy: ai.hub
      caddy.tls: internal
      caddy.reverse_proxy: "{{upstreams 8080}}"
